
You are a Senior Software Engineer.

I implement clean, well thought out code with proper error handling and maintainable architecture.

**Issue Title**: Phase 4: Test Pipeline Execution Engine

**Description**:
Implement the test pipeline definition schema (YAML) and execution orchestrator that runs identical command sequences against both CLIs and compares filesystem state after each step. This phase connects all previous components into a functional test runner.

## Requirements
- FR-2.1: Define test pipelines in YAML format with named sequences
- FR-2.2: High-priority command coverage (init, add, update, delete, relationship add/delete)
- FR-5.1: Execute test pipelines with stdout/stderr capture and timeouts
- FR-5.2: Pre-execution validation of baseline and CLI binaries
- US-4: YAML Pipeline Definitions with readable, version-controlled format
- US-11: Test Runner Execution via single npm script

## Design Guidance
**Pipeline YAML Schema**:
```yaml
# test-cases/element-crud.yaml
name: "Element CRUD Operations"
description: "Test add, update, delete for motivation layer goals"
priority: high

pipelines:
  - name: "Add goal element"
    steps:
      - command: "add motivation goal new-goal --name 'Strategic Goal' --description 'Test goal'"
        files_to_compare:
          - documentation-robotics/model/manifest.yaml
          - documentation-robotics/model/01_motivation/goals.yaml
        expect_exit_code: 0
        expect_stdout_contains: ["Added element", "new-goal"]
      
      - command: "update motivation goal new-goal --name 'Updated Goal'"
        files_to_compare:
          - documentation-robotics/model/01_motivation/goals.yaml
        expect_exit_code: 0
      
      - command: "delete motivation goal new-goal --force"
        files_to_compare:
          - documentation-robotics/model/manifest.yaml
          - documentation-robotics/model/01_motivation/goals.yaml
        expect_exit_code: 0

  - name: "Add relationship"
    steps:
      - command: "relationship add goal-001 realizes service-001"
        files_to_compare:
          - documentation-robotics/model/relationships.yaml
        expect_exit_code: 0
```

**Pipeline Definition Types**:
```typescript
// runner.ts: Pipeline schema types
interface TestSuite {
  name: string;
  description: string;
  priority: 'high' | 'medium' | 'low';
  pipelines: Pipeline[];
}

interface Pipeline {
  name: string;
  steps: PipelineStep[];
}

interface PipelineStep {
  command: string;
  files_to_compare: string[];
  expect_exit_code?: number;
  expect_stdout_contains?: string[];
  expect_stderr_contains?: string[];
  timeout?: number;  // Milliseconds, default 30000
}

interface StepResult {
  command: string;
  pythonOutput: CommandOutput;
  tsOutput: CommandOutput;
  filesystemDiff: FileChange[];
  passed: boolean;
  failures: string[];
}

interface CommandOutput {
  stdout: string;
  stderr: string;
  exitCode: number;
  duration: number;  // Milliseconds
}
```

**Test Runner Implementation**:
```typescript
// runner.ts: Main orchestrator
import { setupTestEnvironment } from './setup';
import { captureSnapshot, diffSnapshots } from './comparator';
import { executeCommand } from './executor';
import YAML from 'yaml';
import { readFile } from 'node:fs/promises';
import { glob } from 'glob';

const PYTHON_CLI = process.env.DR_PYTHON_CLI || '.venv/bin/dr';
const TS_CLI = process.env.DR_TS_CLI || 'node cli/dist/cli.js';

async function runTestSuite(): Promise<void> {
  // Phase 1 integration: Setup test environment
  await setupTestEnvironment();
  
  // Load all test case files
  const testFiles = await glob('test-cases/*.yaml');
  const testSuites: TestSuite[] = [];
  
  for (const file of testFiles) {
    const content = await readFile(file, 'utf-8');
    testSuites.push(YAML.parse(content));
  }
  
  // Execute test suites sequentially (or parallel for independent suites)
  const results: SuiteResult[] = [];
  for (const suite of testSuites) {
    console.log(`Running suite: ${suite.name}`);
    results.push(await runSuite(suite));
  }
  
  // Generate summary report
  const summary = generateSummary(results);
  console.log(summary);
  
  // Exit with appropriate code
  process.exit(results.every(r => r.passed) ? 0 : 1);
}

async function runSuite(suite: TestSuite): Promise<SuiteResult> {
  const pipelineResults: PipelineResult[] = [];
  
  for (const pipeline of suite.pipelines) {
    console.log(`  Pipeline: ${pipeline.name}`);
    pipelineResults.push(await runPipeline(pipeline));
  }
  
  return {
    name: suite.name,
    passed: pipelineResults.every(p => p.passed),
    pipelines: pipelineResults
  };
}

async function runPipeline(pipeline: Pipeline): Promise<PipelineResult> {
  const stepResults: StepResult[] = [];
  const pythonDir = 'cli-validation/test-project/python-cli/documentation-robotics/model';
  const tsDir = 'cli-validation/test-project/ts-cli/documentation-robotics/model';
  
  for (const step of pipeline.steps) {
    console.log(`    Step: ${step.command}`);
    
    // Capture before snapshots
    const pythonBefore = await captureSnapshot(pythonDir);
    const tsBefore = await captureSnapshot(tsDir);
    
    // Execute command on both CLIs
    const pythonOutput = await executeCommand(PYTHON_CLI, step.command, pythonDir);
    const tsOutput = await executeCommand(TS_CLI, step.command, tsDir);
    
    // Capture after snapshots
    const pythonAfter = await captureSnapshot(pythonDir);
    const tsAfter = await captureSnapshot(tsDir);
    
    // Compare filesystem changes
    const pythonChanges = await diffSnapshots(pythonBefore, pythonAfter, pythonDir);
    const tsChanges = await diffSnapshots(tsBefore, tsAfter, tsDir);
    
    // Validate results
    const result = validateStep(step, pythonOutput, tsOutput, pythonChanges, tsChanges);
    stepResults.push(result);
    
    if (!result.passed) {
      console.error(`      FAILED: ${result.failures.join(', ')}`);
      break;  // Stop pipeline on first failure
    }
  }
  
  return {
    name: pipeline.name,
    passed: stepResults.every(s => s.passed),
    steps: stepResults
  };
}
```

**Step Validation Logic**:
```typescript
function validateStep(
  step: PipelineStep,
  pythonOutput: CommandOutput,
  tsOutput: CommandOutput,
  pythonChanges: FileChange[],
  tsChanges: FileChange[]
): StepResult {
  const failures: string[] = [];
  
  // Validate exit codes
  if (step.expect_exit_code !== undefined) {
    if (pythonOutput.exitCode !== step.expect_exit_code) {
      failures.push(`Python CLI exit code: expected ${step.expect_exit_code}, got ${pythonOutput.exitCode}`);
    }
    if (tsOutput.exitCode !== step.expect_exit_code) {
      failures.push(`TS CLI exit code: expected ${step.expect_exit_code}, got ${tsOutput.exitCode}`);
    }
  }
  
  // Validate stdout contains
  if (step.expect_stdout_contains) {
    for (const expected of step.expect_stdout_contains) {
      if (!pythonOutput.stdout.includes(expected)) {
        failures.push(`Python stdout missing: "${expected}"`);
      }
      if (!tsOutput.stdout.includes(expected)) {
        failures.push(`TS stdout missing: "${expected}"`);
      }
    }
  }
  
  // Validate filesystem changes match
  const pythonModified = pythonChanges.filter(c => c.type === 'modified').map(c => c.path);
  const tsModified = tsChanges.filter(c => c.type === 'modified').map(c => c.path);
  
  for (const expectedFile of step.files_to_compare) {
    const pythonChanged = pythonChanges.find(c => c.path === expectedFile);
    const tsChanged = tsChanges.find(c => c.path === expectedFile);
    
    if (!pythonChanged || pythonChanged.type === 'unchanged') {
      failures.push(`Python CLI did not modify: ${expectedFile}`);
    }
    if (!tsChanged || tsChanged.type === 'unchanged') {
      failures.push(`TS CLI did not modify: ${expectedFile}`);
    }
    
    // Compare actual content changes
    if (pythonChanged?.type === 'modified' && tsChanged?.type === 'modified') {
      if (pythonChanged.hash !== tsChanged.hash) {
        failures.push(`File content differs: ${expectedFile}\n${tsChanged.diff}`);
      }
    }
  }
  
  return {
    command: step.command,
    pythonOutput,
    tsOutput,
    filesystemDiff: tsChanges,  // Report TS changes vs baseline
    passed: failures.length === 0,
    failures
  };
}
```

**Pre-Execution Validation**:
```typescript
// Validate environment before running tests
async function validateEnvironment(): Promise<void> {
  // Check baseline exists
  const baselinePath = 'cli-validation/test-project/baseline/documentation-robotics/model';
  const manifestExists = await fileExists(`${baselinePath}/manifest.yaml`);
  if (!manifestExists) {
    throw new Error('Baseline test project not found');
  }
  
  // Check CLI binaries
  try {
    await executeCommand(PYTHON_CLI, '--version', '.');
  } catch (error) {
    throw new Error(`Python CLI not found at: ${PYTHON_CLI}`);
  }
  
  try {
    await executeCommand(TS_CLI, '--version', '.');
  } catch (error) {
    throw new Error(`TS CLI not found at: ${TS_CLI}`);
  }
}
```

**Timeout Handling**:
```typescript
// executor.ts: Command execution with timeout
import { exec } from 'node:child_process';
import { promisify } from 'node:util';

const execAsync = promisify(exec);

async function executeCommand(
  cli: string,
  command: string,
  workingDir: string,
  timeout: number = 30000
): Promise<CommandOutput> {
  const startTime = Date.now();
  
  try {
    const { stdout, stderr } = await execAsync(`${cli} ${command}`, {
      cwd: workingDir,
      timeout,
      maxBuffer: 10 * 1024 * 1024  // 10MB buffer for large outputs
    });
    
    return {
      stdout,
      stderr,
      exitCode: 0,
      duration: Date.now() - startTime
    };
  } catch (error: any) {
    return {
      stdout: error.stdout || '',
      stderr: error.stderr || '',
      exitCode: error.code || 1,
      duration: Date.now() - startTime
    };
  }
}
```

## Acceptance Criteria
- [ ] YAML test case files are loaded from `test-cases/` directory
- [ ] Test runner validates environment (baseline, CLI binaries) before execution
- [ ] Commands execute on both Python and TypeScript CLIs with timeout handling
- [ ] Filesystem snapshots are captured before and after each command
- [ ] Exit codes, stdout, and stderr are validated per step expectations
- [ ] Pipeline execution stops on first step failure
- [ ] Test runner exits with code 0 for all passing, non-zero for failures
- [ ] `npm run test:compatibility` executes full test suite
- [ ] Code is reviewed and approved

## Dependencies
Phase 1, Phase 2, Phase 3 (requires setup, comparator, normalization)

## Parent Issue
Part of #91

## Discussion
This work is detailed in discussion [92](https://github.com/tinkermonkey/documentation_robotics/discussions/92)

---


## Previous Work and Feedback

The following is the complete history of agent outputs and feedback for this issue.
This includes outputs from ALL previous stages (design, testing, QA, etc.) and any
user feedback. If this issue was returned from testing or QA, pay special attention
to their feedback and address all issues they identified.

## Output from Software Architect

**software_architect** (agent):
# Architecture Design

---

Now I have a comprehensive understanding of the existing infrastructure. Let me review the command implementations to understand the file modification patterns.Now I have a comprehensive understanding of the existing architecture, test infrastructure, and baseline test project. Let me produce the architectural analysis.

## System Architecture

### Overview

The CLI Compatibility Test Suite requires a **parallel execution architecture** that operates both CLIs against isolated copies of the same baseline model, then performs **structural filesystem comparison** to verify behavioral equivalence.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Test Suite Orchestrator                        â”‚
â”‚                    (cli-validation/test-suite/)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Test Case   â”‚â”€â”€â”€â”€â–¶â”‚   Pipeline    â”‚â”€â”€â”€â”€â–¶â”‚   Filesystem      â”‚  â”‚
â”‚  â”‚  Definitions â”‚     â”‚   Executor    â”‚     â”‚   Comparator      â”‚  â”‚
â”‚  â”‚  (YAML)      â”‚     â”‚               â”‚     â”‚                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                               â”‚                       â”‚             â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â–¼                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Comparison Engine                          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚  â”‚
â”‚  â”‚  â”‚   YAML     â”‚  â”‚   JSON     â”‚  â”‚   Text     â”‚             â”‚  â”‚
â”‚  â”‚  â”‚ Normalizer â”‚  â”‚ Normalizer â”‚  â”‚ Normalizer â”‚             â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   python-cli/       â”‚               â”‚   ts-cli/           â”‚
â”‚   (baseline copy)   â”‚               â”‚   (baseline copy)   â”‚
â”‚                     â”‚               â”‚                     â”‚
â”‚   Python CLI        â”‚               â”‚   TypeScript CLI    â”‚
â”‚   (.venv/bin/dr)    â”‚               â”‚   (node dist/cli.js)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directory Structure

```
cli-validation/
â”œâ”€â”€ test-project/
â”‚   â”œâ”€â”€ baseline/                    # EXISTING: 59 elements, 15 relationships
â”‚   â”‚   â””â”€â”€ documentation-robotics/
â”‚   â”‚       â””â”€â”€ model/
â”‚   â”‚           â”œâ”€â”€ manifest.yaml
â”‚   â”‚           â”œâ”€â”€ relationships.yaml
â”‚   â”‚           â””â”€â”€ 01_motivation/ ... 12_testing/
â”‚   â”œâ”€â”€ python-cli/                  # RUNTIME: Fresh copy per test run
â”‚   â””â”€â”€ ts-cli/                      # RUNTIME: Fresh copy per test run
â”‚
â””â”€â”€ test-suite/                      # NEW: Test infrastructure
    â”œâ”€â”€ runner.ts                    # Test execution orchestrator
    â”œâ”€â”€ comparator.ts                # Filesystem comparison engine
    â”œâ”€â”€ normalizers/
    â”‚   â”œâ”€â”€ yaml-normalizer.ts       # YAML content normalization
    â”‚   â”œâ”€â”€ json-normalizer.ts       # JSON content normalization
    â”‚   â””â”€â”€ timestamp-normalizer.ts  # ISO-8601 timestamp handling
    â”œâ”€â”€ test-cases/
    â”‚   â”œâ”€â”€ element-crud.yaml        # Element lifecycle tests
    â”‚   â”œâ”€â”€ relationships.yaml       # Relationship management tests
    â”‚   â”œâ”€â”€ validation.yaml          # Validation workflow tests
    â”‚   â”œâ”€â”€ export.yaml              # Export format tests
    â”‚   â””â”€â”€ changeset.yaml           # Changeset operation tests
    â”œâ”€â”€ reporters/
    â”‚   â”œâ”€â”€ console-reporter.ts      # Terminal output
    â”‚   â””â”€â”€ junit-reporter.ts        # CI/CD integration
    â””â”€â”€ package.json                 # Test suite dependencies
```

## Scalability Design

### Test Isolation Model

Each test pipeline execution follows a **clean-room pattern**:

1. **Pre-test**: Copy `baseline/` â†’ `python-cli/` and `ts-cli/`
2. **Execution**: Run identical command sequences in parallel
3. **Comparison**: Diff modified files between both directories
4. **Post-test**: Preserve artifacts on failure, cleanup on success

This isolation prevents test cross-contamination and enables parallel test execution for independent pipelines.

### Parallel Execution Strategy

```typescript
// Independent pipelines can execute concurrently
const results = await Promise.all([
  runPipeline('element-crud'),      // No shared state
  runPipeline('export-formats'),    // No shared state
  // Sequential tests within each pipeline
]);
```

### Performance Considerations

| Factor | Mitigation |
|--------|------------|
| Baseline copy overhead (~60 files) | rsync with hardlinks for unchanged files |
| CLI startup latency | Warm-up execution before timing-sensitive tests |
| Large export files | Stream-based comparison, avoid memory buffering |
| Parallel I/O contention | Rate-limit concurrent filesystem operations |

## Established Patterns

### Reuse from Existing Differential Test Infrastructure

The project already has differential testing infrastructure in `cli/tests/differential/` that provides:

| Component | Source | Reuse Strategy |
|-----------|--------|----------------|
| Command execution | `runner.ts` | Adapt `executeCommand()` for working directory isolation |
| Output comparison | `comparator.ts` | Extend with filesystem diff capabilities |
| Test case format | `test-cases.yaml` | Extend YAML schema for file comparison specs |
| Normalization | `normalizeJson()` | Leverage for JSON/YAML content comparison |

### New Patterns Required

**1. Filesystem State Capture**

```typescript
interface FilesystemSnapshot {
  files: Map<string, {
    exists: boolean;
    hash: string;        // Content hash for quick diff
    mtime: number;       // For detecting modifications
    content?: string;    // Lazy-loaded for diff generation
  }>;
}

async function captureSnapshot(directory: string): Promise<FilesystemSnapshot>;
async function diffSnapshots(before: FilesystemSnapshot, after: FilesystemSnapshot): Promise<FileChange[]>;
```

**2. Pipeline Step Definition**

```yaml
# test-cases/element-crud.yaml
pipelines:
  - name: "Add element lifecycle"
    steps:
      - command: "dr add motivation goal new-goal --name 'New Goal'"
        expect_files_changed:
          - path: "documentation-robotics/model/manifest.yaml"
            changes: ["layers.motivation.elements.goal"]
          - path: "documentation-robotics/model/01_motivation/goals.yaml"
            changes: ["+new-goal"]  # New key added
```

**3. Content Normalization Pipeline**

```typescript
// Order matters: apply normalizations in sequence
const normalizers = [
  stripTimestamps,      // Remove ISO-8601 timestamps
  canonicalizePaths,    // Normalize path separators
  sortYamlKeys,         // Deterministic key ordering
  trimWhitespace,       // Remove trailing whitespace
];

function normalize(content: string, type: 'yaml' | 'json'): string {
  return normalizers.reduce((c, fn) => fn(c, type), content);
}
```

## Component Reuse

### Direct Reuse

| Component | Location | Usage |
|-----------|----------|-------|
| YAML parser | `cli/package.json` â†’ `yaml@2.8.2` | Parse layer files for structural comparison |
| Test framework | `bun:test` | Consistent with existing test infrastructure |
| CLI execution | Existing `runner.ts` patterns | Spawn process with timeout handling |

### Adaptation Required

**Existing comparator.ts â†’ New filesystem comparator**

The existing `comparator.ts` handles stdout/stderr comparison. The new comparator needs:

- Directory tree diffing (file additions/deletions)
- Content comparison with normalization
- Structured YAML/JSON comparison (not just text diff)
- Unified diff output for debugging

**Existing test-cases.yaml â†’ Extended schema**

Current format focuses on command output. New format needs:

```yaml
# Extended schema additions
steps:
  - command: "..."
    working_dir: "{python-cli | ts-cli}"  # NEW
    files_to_compare:                       # NEW
      - manifest.yaml
      - 01_motivation/*.yaml
    expect_exit_code: 0
    expect_stdout_contains: ["Added element"]  # Existing
```

## Implementation Plan

### Phase 1: Test Infrastructure Foundation

1. **Create test-suite directory structure**
   - `/cli-validation/test-suite/` with package.json, tsconfig.json
   - Integrate with existing `cli/package.json` scripts

2. **Implement baseline copy mechanism**
   - `setup.ts`: Copy baseline â†’ python-cli/ and ts-cli/
   - Use `fs.cp()` with recursive option
   - Cleanup utility for post-test

3. **Implement filesystem snapshot engine**
   - Capture file tree state before/after commands
   - Generate content hashes for quick diff detection
   - Lazy content loading for actual diff generation

### Phase 2: Comparison Engine

4. **Implement YAML/JSON normalizers**
   - Timestamp stripping (ISO-8601 patterns)
   - Key ordering canonicalization
   - Whitespace normalization
   - Path separator normalization

5. **Implement diff reporter**
   - Unified diff format for file content differences
   - Summary of added/modified/deleted files
   - Integration with Bun test framework assertions

### Phase 3: Test Case Authoring

6. **Define test pipeline YAML schema**
   - Pipeline metadata (name, description, priority)
   - Step definitions (command, expected files, comparisons)
   - Normalization exceptions per test

7. **Author high-priority test cases**
   - Element CRUD: `add`, `update`, `delete` across all 12 layers
   - Relationships: `relationship add`, `relationship delete`
   - Manifest updates: Element counts, timestamps, statistics

### Phase 4: Extended Coverage

8. **Author export test cases**
   - ArchiMate, OpenAPI, PlantUML, Markdown, GraphML
   - Compare generated file structures with normalization

9. **Author changeset test cases**
   - `changeset create`, `apply`, `revert`
   - Verify `.dr/changesets/` directory contents

10. **CI/CD integration**
    - JUnit reporter for GitHub Actions
    - npm script: `test:fs-compatibility`

### Critical Implementation Notes

**CLI Path Configuration**

```typescript
const PYTHON_CLI = process.env.DR_PYTHON_CLI || '.venv/bin/dr';
const TS_CLI = process.env.DR_TS_CLI || 'node cli/dist/cli.js';
```

**Known Behavioral Differences**

From `/cli-validation/PYTHON_VS_TS_COMPARISON.md`:

1. **Path Resolution**: Python uses `documentation-robotics/model/`, TypeScript now supports both layouts
2. **Element ID Generation**: Python auto-generates `{layer}.{key}`, TypeScript uses key directly
3. **Relationship Storage**: Python stores in `relationships.yaml`, TypeScript stores on element objects

These differences should be documented in test cases with appropriate normalization or expected failures.

**Test Isolation Verification**

Each test should verify that:
- No files outside the test directory are modified
- Both CLIs start from identical baseline state
- File timestamps don't affect comparison results

---

**Architectural Decision: Location of Test Suite**

| Option | Pros | Cons |
|--------|------|------|
| `/cli-validation/test-suite/` | Isolated from CLI code, clear ownership | Requires separate dependency management |
| `/cli/tests/fs-compatibility/` | Shares CLI dependencies | Couples test infrastructure to CLI package |

**Recommendation**: `/cli-validation/test-suite/` with its own `package.json` that references `cli/dist/cli.js`. This maintains separation between the test infrastructure (which tests both CLIs) and the TypeScript CLI under test.

---
_Generated by Orchestrator Bot ğŸ¤–_
_Processed by the software_architect agent_

IMPORTANT: Review all feedback carefully and address every issue that is not already addressed.


